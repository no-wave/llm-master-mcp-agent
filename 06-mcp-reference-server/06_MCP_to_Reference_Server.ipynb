{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc712d2-8b62-4098-a986-76ec60c795c4",
   "metadata": {},
   "source": [
    "# Connecting MCP Chatbot to Reference Servers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7159b5-02ba-413a-b30c-4f7725379c46",
   "metadata": {},
   "source": [
    "## Update MCP Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459d98de-3fc7-4d1e-9f7c-e926f106caae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mcp_project/mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_project/mcp_chatbot.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, TypedDict\n",
    "from contextlib import AsyncExitStack\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API client 초기화\n",
    "import config\n",
    "client = OpenAI(api_key=config.API_KEY)\n",
    "\n",
    "# 도구 정의를 위한 TypedDict\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "class MCP_ChatBot:\n",
    "\n",
    "    def __init__(self):\n",
    "        # 여러 MCP 세션 관리\n",
    "        self.sessions: List[ClientSession] = []\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.available_tools: List[ToolDefinition] = []\n",
    "        \n",
    "        # 도구 이름 ↔ 해당 도구를 제공하는 세션 매핑\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {}\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_config: dict) -> None:\n",
    "        \"\"\"단일 MCP 서버에 연결\"\"\"\n",
    "        try:\n",
    "            params = StdioServerParameters(**server_config)\n",
    "            # stdio transport 생성\n",
    "            read, write = await self.exit_stack.enter_async_context(stdio_client(params))\n",
    "            session = await self.exit_stack.enter_async_context(ClientSession(read, write))\n",
    "            await session.initialize()\n",
    "            self.sessions.append(session)\n",
    "\n",
    "            # 도구 목록 조회\n",
    "            response = await session.list_tools()\n",
    "            print(f\"\\nConnected to {server_name} with tools:\", [t.name for t in response.tools])\n",
    "            for tool in response.tools:\n",
    "                # 세션과 도구 매핑\n",
    "                self.tool_to_session[tool.name] = session\n",
    "                self.available_tools.append({\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"input_schema\": tool.inputSchema\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self) -> None:\n",
    "        \"\"\"설정 파일(server_config.json)에 정의된 모든 서버에 연결\"\"\"\n",
    "        try:\n",
    "            with open(\"server_config.json\", \"r\") as f:\n",
    "                cfg = json.load(f)\n",
    "            for name, params in cfg.get(\"mcpServers\", {}).items():\n",
    "                await self.connect_to_server(name, params)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading server configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def process_query(self, query: str) -> None:\n",
    "        # 사용자 메시지로 대화 시작\n",
    "        messages = [{\"role\": \"user\", \"content\": query}]\n",
    "        # OpenAI 함수 스펙으로 도구 정의\n",
    "        functions = [\n",
    "            {\"name\": t[\"name\"], \"description\": t[\"description\"], \"parameters\": t[\"input_schema\"]}\n",
    "            for t in self.available_tools\n",
    "        ]\n",
    "\n",
    "        while True:\n",
    "            # OpenAI 함수 호출 자동화\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                functions=functions,\n",
    "                function_call=\"auto\",\n",
    "                max_tokens=2024,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            msg = resp.choices[0].message\n",
    "\n",
    "            # 도구 호출 요청 처리\n",
    "            if getattr(msg, \"function_call\", None):\n",
    "                name = msg.function_call.name\n",
    "                args = json.loads(msg.function_call.arguments)\n",
    "                print(f\"Calling tool {name} with args {args}\")\n",
    "                session = self.tool_to_session[name]\n",
    "                result = await session.call_tool(name, arguments=args)\n",
    "                # 함수 결과를 대화에 추가\n",
    "                messages.append({\"role\": \"function\", \"name\": name, \"content\": result.content})\n",
    "                # 반복하여 후속 응답 처리\n",
    "                continue\n",
    "\n",
    "            # 일반 응답 출력 및 종료\n",
    "            print(msg.content)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": msg.content})\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self) -> None:\n",
    "        print(\"\\nMCP Chatbot Started! Type queries or 'quit' to exit.\")\n",
    "        while True:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "            await self.process_query(query)\n",
    "            print()\n",
    "\n",
    "    async def cleanup(self) -> None:\n",
    "        \"\"\"모든 리소스 정리\"\"\"\n",
    "        await self.exit_stack.aclose()\n",
    "\n",
    "async def main() -> None:\n",
    "    nest_asyncio.apply()\n",
    "    chatbot = MCP_ChatBot()\n",
    "    try:\n",
    "        await chatbot.connect_to_servers()\n",
    "        await chatbot.chat_loop()\n",
    "    finally:\n",
    "        await chatbot.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
